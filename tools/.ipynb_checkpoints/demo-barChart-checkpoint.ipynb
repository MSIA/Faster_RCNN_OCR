{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Tensorflow Faster R-CNN\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Xinlei Chen, based on code from Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Demo script showing detections in sample images.\n",
    "\n",
    "See README.md for installation instructions before running.\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "from model.config import cfg\n",
    "from model.test import im_detect\n",
    "from model.nms_wrapper import nms\n",
    "\n",
    "from utils.timer import Timer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "import argparse\n",
    "\n",
    "from nets.vgg16 import vgg16\n",
    "from nets.resnet_v1 import resnetv1\n",
    "\n",
    "import torch\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "CLASSES = ('__background__',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "           'cow', 'diningtable', 'dog', 'horse',\n",
    "           'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "\n",
    "NETS = {'vgg16': ('vgg16_faster_rcnn_iter_%d.pth',),'res101': ('res101_faster_rcnn_iter_%d.pth',)}\n",
    "DATASETS= {'pascal_voc': ('voc_2007_trainval',),'pascal_voc_0712': ('voc_2007_trainval+voc_2012_trainval',)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_detections(im, class_name, dets, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    if len(inds) == 0:\n",
    "        return\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo(net, image_name):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "    im_file = os.path.join(cfg.DATA_DIR, 'VOCdevkit2007', 'VOC2007', 'ImageSets', 'Main', image_name)\n",
    "    im = cv2.imread(im_file)\n",
    "    print('Demo for {}'.format(im_file))\n",
    "\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(net, im)\n",
    "    timer.toc()\n",
    "    print('Detection took {:.3f}s for {:d} object proposals'.format(timer.total_time(), boxes.shape[0]))\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    CONF_THRESH = 0.7\n",
    "    NMS_THRESH = 0.3\n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(torch.from_numpy(dets), NMS_THRESH)\n",
    "        dets = dets[keep.numpy(), :]\n",
    "        vis_detections(im, cls, dets, thresh=CONF_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demonet = 'vgg16' # Network to use [vgg16 res101]\n",
    "dataset = 'pascal_voc' # Trained dataset [pascal_voc pascal_voc_0712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of anchors =  20\n",
      "/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(1)\n",
    "if True:\n",
    "    cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "\n",
    "    # model path\n",
    "    #saved_model = os.path.join('../output', demonet, DATASETS[dataset][0], 'default',\n",
    "    #                          NETS[demonet][0] %(70000 if dataset == 'pascal_voc' else 110000))\n",
    "    #saved_model = '../output.back/vgg16/custom_2018_trainval_diff/default/vgg16_faster_rcnn_iter_4000.pth'\n",
    "    #'''\n",
    "    saved_model = '../output/vgg16/barcharts_2018_trainval/default/vgg16_faster_rcnn_iter_200000.pth' # 4-class{back, tit, xla, yla}\n",
    "    CLASSES = ('__background__', 'title', 'xlabel', 'ylabel',  'xticks', 'yticks', 'bars', 'legends')\n",
    "    '''\n",
    "    saved_model = '../../project2018/test1/vgg16_faster_rcnn_iter_40000.pth' # 3-class{back, text, ylabel}\n",
    "    CLASSES = ('__background__', 'text', 'ylabel')\n",
    "    '''\n",
    "\n",
    "    if not os.path.isfile(saved_model):\n",
    "        raise IOError(('{:s} not found.\\nDid you download the proper networks from '\n",
    "                       'our server and place them properly?').format(saved_model))\n",
    "\n",
    "    # load network\n",
    "    if demonet == 'vgg16':\n",
    "        net = vgg16()\n",
    "    elif demonet == 'res101':\n",
    "        net = resnetv1(num_layers=101)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    net.create_architecture(len(CLASSES),\n",
    "                            tag='default', anchor_scales=[8, 16, 32, 64], anchor_ratios=(0.2,0.5,1,2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('../output/vgg16/barcharts_2018_trainval/default/vgg16_faster_rcnn_iter_200000.pth')\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():    \n",
    "    name = k.replace('module.','') #[7:] # remove `module.`\n",
    "    #print(name)\n",
    "    new_state_dict[name] = v\n",
    "net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vis_detections1(ax, im, class_name, dets, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    if len(inds) == 0:\n",
    "        return\n",
    "\n",
    "\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "    '''\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),   fontsize=14)    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demo1(net, image_name, CONF_THRESH = 0.7):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    #im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "    #im_file = os.path.join(cfg.DATA_DIR, 'VOCdevkit2007', 'VOC2007', 'JPEGImages', image_name)\n",
    "    \n",
    "    #im_file = '/home/xliu/checkImageFromGoogle/bs1.png'\n",
    "    \n",
    "    #im_file = '/home/xliu/pytorch-faster-rcnn/KNOWLEDGE_FROM_CHARTS/SEMICON_BARS/semi_equipment_materials.jpg'\n",
    "    im_file = image_name\n",
    "    im = cv2.imread(im_file)\n",
    "    print('Demo for {}'.format(im_file))\n",
    "\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(net, im)\n",
    "    timer.toc()\n",
    "    print('Detection took {:.3f}s for {:d} object proposals'.format(timer.total_time(), boxes.shape[0]))\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    NMS_THRESH = 0.3\n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "    #for cls_ind, cls in enumerate(CLASSES[0:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(torch.from_numpy(dets), NMS_THRESH)\n",
    "        dets = dets[keep.numpy(), :]\n",
    "\n",
    "        vis_detections1(ax, im, cls, dets, thresh=CONF_THRESH)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 __background__\n",
      "1 title\n",
      "2 xlabel\n",
      "3 ylabel\n",
      "4 xticks\n",
      "5 yticks\n",
      "6 bars\n",
      "7 legends\n"
     ]
    }
   ],
   "source": [
    "for cls_ind, cls in enumerate(CLASSES[0:]):\n",
    "    print(cls_ind, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a1cf7e235dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mim_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'1.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmypath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/VOCdevkit2018/barcharts2018/JPEGImages/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mim_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#im_names =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "net = net.cuda()\n",
    "    \n",
    "    #im_names = ['000456.jpg', '000542.jpg', '001150.jpg',\n",
    "    #            '001763.jpg', '004545.jpg']\n",
    "im_names = ['1.jpg']\n",
    "mypath = '../data/VOCdevkit2018/barcharts2018/JPEGImages/'\n",
    "im_names = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "#im_names = \n",
    "for im_name in im_names[:10]:\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    #print('Demo for data/demo/{}'.format(im_name))\n",
    "    try:\n",
    "        demo1(net, im_name, CONF_THRESH = 0.3)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Type Unsupported\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Demo for ../data/VOCdevkit2018/barcharts2018/JPEGImages/15828.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py:322: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  rpn_cls_prob_reshape = F.softmax(rpn_cls_score_reshape)\n",
      "/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py:359: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_prob = F.softmax(cls_score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 1.5205  0.7127  1.1548  0.0012  0.1634  0.0012  0.0282  0.3570  0.3695  1.0508\n",
      "\n",
      "Columns 10 to 19 \n",
      " 0.0012  0.0012  0.0012  0.0012  0.0249  0.2498  0.0012  1.2791  0.5564  0.2384\n",
      "\n",
      "Columns 20 to 29 \n",
      " 2.5012  0.0012  0.4798  0.0366  0.0035  0.0012  0.0012  0.0203  0.0322  0.3037\n",
      "\n",
      "Columns 30 to 39 \n",
      " 0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.4213  0.0012  0.0012\n",
      "\n",
      "Columns 40 to 49 \n",
      " 0.3881  0.0012  1.0124  0.0012  0.0210  0.0012  0.3026  0.4576  0.0012  0.0012\n",
      "\n",
      "Columns 50 to 59 \n",
      " 0.0012  0.0012  0.0012  0.0130  0.0012  0.0012  0.0169  0.0642  0.0012  0.0573\n",
      "\n",
      "Columns 60 to 69 \n",
      " 0.0012  0.0045  1.1498  0.0012  0.0026  1.2233  0.0012  0.6631  0.0012  0.0012\n",
      "\n",
      "Columns 70 to 79 \n",
      " 0.0012  0.0012  0.0012  0.0322  0.0012  0.0251  1.5341  0.0186  0.0012  0.0012\n",
      "\n",
      "Columns 80 to 89 \n",
      " 0.0012  0.0192  0.3364  0.0012  0.0012  0.0012  0.0344  0.0012  0.0012  0.0182\n",
      "\n",
      "Columns 90 to 99 \n",
      " 0.0012  0.6488  0.1317  0.0012  0.0328  0.0012  0.0012  0.0012  0.0012  0.0012\n",
      "\n",
      "Columns 100 to 109 \n",
      " 0.0459  0.7956  1.1948  0.6010  0.0123  0.0012  0.0012  0.0012  0.0073  0.0012\n",
      "\n",
      "Columns 110 to 119 \n",
      " 0.0012  0.5240  0.0012  0.0012  0.1406  0.1253  0.0012  0.0012  0.0012  0.0033\n",
      "\n",
      "Columns 120 to 129 \n",
      " 0.0072  0.0012  0.0012  0.0012  0.5896  2.1251  0.0012  0.0012  0.0092  0.0012\n",
      "\n",
      "Columns 130 to 139 \n",
      " 0.0120  0.0012  0.0012  0.0012  0.0012  1.0774  0.0276  0.2720  0.2159  0.3969\n",
      "\n",
      "Columns 140 to 149 \n",
      " 0.0248  0.0493  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.3868  0.0012\n",
      "\n",
      "Columns 150 to 159 \n",
      " 0.3514  0.0012  0.0012  0.0339  0.0012  0.0012  0.0012  0.0012  0.5240  0.0017\n",
      "\n",
      "Columns 160 to 169 \n",
      " 0.0012  0.0086  0.0012  0.8510  0.0563  0.0012  0.1536  0.0012  0.0349  0.0012\n",
      "\n",
      "Columns 170 to 179 \n",
      " 0.0377  0.0012  0.0235  0.0551  0.0741  0.0012  0.0012  0.0067  0.4269  0.0518\n",
      "\n",
      "Columns 180 to 189 \n",
      " 0.2056  0.0924  0.0012  0.9106  0.1542  0.2390  0.3374  0.0397  0.0012  0.3125\n",
      "\n",
      "Columns 190 to 199 \n",
      " 0.0012  0.0230  0.0012  0.0014  0.1207  0.0042  0.0012  0.5800  0.0012  0.0538\n",
      "\n",
      "Columns 200 to 209 \n",
      " 0.1229  1.9045  0.0012  0.0012  0.0012  0.0012  0.7197  0.0012  0.0012  1.9857\n",
      "\n",
      "Columns 210 to 219 \n",
      " 0.8212  0.1711  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.1741  1.1592\n",
      "\n",
      "Columns 220 to 229 \n",
      " 0.0860  0.0012  0.0012  0.0230  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012\n",
      "\n",
      "Columns 230 to 239 \n",
      " 0.0012  0.4388  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012  0.0012\n",
      "\n",
      "Columns 240 to 249 \n",
      " 0.0012  0.0289  0.0012  0.0012  0.0012  0.0012  0.0631  0.0012  1.8114  0.0012\n",
      "\n",
      "Columns 250 to 259 \n",
      " 0.0012  0.0012  0.0012  0.4744  0.0012  1.0712  0.0012  0.0012  0.0012  0.0012\n",
      "\n",
      "Columns 260 to 269 \n",
      " 0.0676  0.0012  0.0012  0.0012  1.3949  1.4215  0.0012  0.1939  0.1309  0.5748\n",
      "\n",
      "Columns 270 to 279 \n",
      " 0.3237  0.0012  0.0012  0.0012  0.0012  1.2520  0.0012  1.1299  1.1825  0.9165\n",
      "\n",
      "Columns 280 to 289 \n",
      " 0.0012  0.3897  0.7962  0.0012  0.0012  0.0012  0.4776  0.0012  0.3865  0.0056\n",
      "\n",
      "Columns 290 to 299 \n",
      " 0.0012  0.9083  0.0012  0.0202  0.9167  1.8641  0.0024  1.2687  0.0012  0.0012\n",
      "[torch.cuda.FloatTensor of size 1x300 (GPU 1)]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a4612deff617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print('Demo for data/demo/{}'.format(im_name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdemo1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONF_THRESH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7275b121133c>\u001b[0m in \u001b[0;36mdemo1\u001b[0;34m(net, image_name, CONF_THRESH)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Detection took {:.3f}s for {:d} object proposals'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/model/test.py\u001b[0m in \u001b[0;36mim_detect\u001b[0;34m(net, im)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'im_info'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'im_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mim_scales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36mtest_image\u001b[0;34m(self, image, im_info)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TEST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0mcls_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cls_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cls_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, im_info, gt_boxes, gt_texts, mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TEST'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;31m# from roi_pool layer to predicted texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0mtext_crnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stn_crnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_crnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/nets/network.py\u001b[0m in \u001b[0;36m_stn_crnn\u001b[0;34m(self, pool_crnn)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_stn_crnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_crnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mtext_crnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrnn_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_crnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_pred\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_crnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext_crnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/crnn/nets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;31m#, ang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/izola/xyl/pytorch-faster-rcnn/tools/../lib/crnn/ocr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mroi0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xliu/.conda/envs/dl/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "#net = net.cuda()\n",
    "net = net.eval()\n",
    "    \n",
    "    #im_names = ['000456.jpg', '000542.jpg', '001150.jpg',\n",
    "    #            '001763.jpg', '004545.jpg']\n",
    "im_names = ['1.jpg']\n",
    "mypath = '../data/VOCdevkit2018/barcharts2018/JPEGImages/'\n",
    "im_names = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "#im_names = \n",
    "for im_name in im_names[:10]:\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    #print('Demo for data/demo/{}'.format(im_name))\n",
    "    demo1(net, im_name, CONF_THRESH = 0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mypath = '/home/xliu/pytorch-faster-rcnn/KNOWLEDGE_FROM_CHARTS/SEMICON_BARS/'\n",
    "files = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
